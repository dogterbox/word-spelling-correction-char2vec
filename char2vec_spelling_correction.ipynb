{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words Spelling Correction using Char2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load corpus: **PyThaiNLP** thai word corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.corpus import thai_words\n",
    "import numpy as np\n",
    "\n",
    "words = thai_words()\n",
    "words = np.array(list(words))  # to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocabs:  62847\n"
     ]
    }
   ],
   "source": [
    "print('Number of vocabs: ', len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ปรเมศวร์' 'บาดหมาย' 'สำริด' 'เสม็ดชุน' 'หมักหมม' 'อัตรชะ' 'ประหารชีวิต'\n",
      " 'ประนีประนอม' 'คณะมัณฑนศิลป์' 'รักยม']\n"
     ]
    }
   ],
   "source": [
    "print(words[:10])  # sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert array to string separate by '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_str = '\\n'.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ปรเมศวร์\n",
      "บาดหมาย\n",
      "สำริด\n",
      "เสม็ดชุน\n",
      "หมักหมม\n",
      "อัตรชะ\n",
      "ประหารชีวิต\n",
      "ประนีประนอม\n",
      "คณะมัณฑนศิลป์\n",
      "รักยม\n",
      "ความรู้สึ\n"
     ]
    }
   ],
   "source": [
    "print(words_str[:100])  # sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert string to char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_char = list(words_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ป', 'ร', 'เ', 'ม', 'ศ', 'ว', 'ร', '์', '\\n', 'บ', 'า', 'ด', 'ห', 'ม', 'า', 'ย', '\\n', 'ส', 'ำ', 'ร', 'ิ', 'ด', '\\n', 'เ', 'ส', 'ม', '็', 'ด', 'ช', 'ุ', 'น', '\\n', 'ห', 'ม', 'ั', 'ก', 'ห', 'ม', 'ม', '\\n', 'อ', 'ั', 'ต', 'ร', 'ช', 'ะ', '\\n', 'ป', 'ร', 'ะ', 'ห', 'า', 'ร', 'ช', 'ี', 'ว', 'ิ', 'ต', '\\n', 'ป', 'ร', 'ะ', 'น', 'ี', 'ป', 'ร', 'ะ', 'น', 'อ', 'ม', '\\n', 'ค', 'ณ', 'ะ', 'ม', 'ั', 'ณ', 'ฑ', 'น', 'ศ', 'ิ', 'ล', 'ป', '์', '\\n', 'ร', 'ั', 'ก', 'ย', 'ม', '\\n', 'ค', 'ว', 'า', 'ม', 'ร', 'ู', '้', 'ส', 'ึ']\n"
     ]
    }
   ],
   "source": [
    "print(words_char[:100])  # sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data to **words-char.txt** file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('words-char.txt', mode='w', encoding='utf-8') as file:\n",
    "    file.write(' '.join(words_char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Char2Vec Model\n",
    "Using FastText traing Word2Vec model on **character level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load file and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_unsupervised('words-char.txt', epoch=200, ws=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of char:  73\n"
     ]
    }
   ],
   "source": [
    "print('Number of char: ', len(model.words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create word vector on character level model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_vec = [model.get_sentence_vector(' '.join(list(word))) for word in words]\n",
    "words_vec = np.array(words_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Spelling Correction\n",
    "Using **nearest neighbors model** to find **word similarity** for get word suggestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training\n",
    "- X: word vector\n",
    "- y: word/vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "X, y = words_vec, words\n",
    "nbrs = NearestNeighbors().fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save All Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model.save_model('char2vec.bin')  # fasttext model\n",
    "joblib.dump(words, 'words.joblib')\n",
    "joblib.dump(nbrs, 'nbrs.joblib');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import joblib\n",
    "\n",
    "model = fasttext.load_model('char2vec.bin')\n",
    "words = joblib.load('words.joblib')\n",
    "nbrs = joblib.load('nbrs.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_input = ['การบด้าน', 'สวัดี', 'vออกเลอร์', 'ปละเทศไทยย', 'อรอย']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "การบด้าน \n",
      "---> ['การบ้าน' 'การอาบน้ำ' 'ทำการบ้าน' 'การกวาดล้าง' 'กลับด้าน']\n",
      "สวัดี \n",
      "---> ['สวัสดี' 'วสวัดดี' 'วิดัสดี' 'ดบัสวี' 'วนัสบดี']\n",
      "vออกเลอร์ \n",
      "---> ['ล็อคเกอร์' 'ล็อกเกอร์' 'เดอะรอยัลกอล์ฟ' 'โอเรกอน' 'ร็อกกี้เฟลเลอร์']\n",
      "ปละเทศไทยย \n",
      "---> ['ประเทศไทย' 'ไปรษณีย์ลงทะเบียน' 'การปิโตรเลียมแห่งประเทศไทย' 'ลายเทศ'\n",
      " 'สถานีวิทยุกระจายเสียงแห่งประเทศไทย']\n",
      "อรอย \n",
      "---> ['รอย' 'รอคอย' 'อร่อย' 'รอยต่อ' 'ออยเลอร์']\n"
     ]
    }
   ],
   "source": [
    "word_input_vec = [model.get_sentence_vector(' '.join(list(word))) for word in words_input]\n",
    "indices = nbrs.kneighbors(word_input_vec, 5, False)  # n_neighbors is 5\n",
    "suggestion = words[indices]\n",
    "\n",
    "for w, s in zip(words_input, suggestion):\n",
    "    print(f'{w} \\n---> {s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook char2vec_spelling_correction.ipynb to markdown\n",
      "[NbConvertApp] Writing 3777 bytes to char2vec_spelling_correction.md\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to markdown char2vec_spelling_correction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
